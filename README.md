# INCIScraper ğŸš€

INCIScraper, [INCIDecoder.com](https://incidecoder.com) ve [EU CosIng veritabanÄ±](https://ec.europa.eu/growth/tools-databases/cosing/) Ã¼zerinden kapsamlÄ± kozmetik veri toplama iÃ§in geliÅŸtirilmiÅŸ yÃ¼ksek performanslÄ± bir web scraper'Ä±dÄ±r. Paralel iÅŸleme, akÄ±llÄ± Ã¶nbellekleme ve optimize edilmiÅŸ kazÄ±ma algoritmalarÄ± ile bÃ¼yÃ¼k veri setlerini verimli ÅŸekilde toplar.

## âœ¨ Ã–ne Ã‡Ä±kan Ã–zellikler

### ğŸ”¥ Performans OptimizasyonlarÄ±
- **Paralel HTTP Ä°stekleri**: ThreadPoolExecutor ile eÅŸzamanlÄ± veri kazÄ±ma
- **Adaptive Rate Limiting**: Dinamik gecikme yÃ¶netimi ile maksimum hÄ±z
- **Batch Database Operations**: Toplu veritabanÄ± iÅŸlemleri ile I/O optimizasyonu
- **LRU Cache**: Bellek tabanlÄ± akÄ±llÄ± Ã¶nbellekleme sistemi
- **Optimized CosIng Scraping**: %60 daha hÄ±zlÄ± ingredient veri kazÄ±ma

### ğŸ›¡ï¸ GÃ¼venilirlik & DayanÄ±klÄ±lÄ±k
- **Resume Capability**: Kesintili oturumlarda kaldÄ±ÄŸÄ± yerden devam
- **Error Recovery**: AkÄ±llÄ± hata yÃ¶netimi ve otomatik yeniden deneme
- **Progress Tracking**: GerÃ§ek zamanlÄ± ilerleme takibi ve ETA
- **Comprehensive Logging**: DetaylÄ± loglama ve hata ayÄ±klama

### ğŸ“Š KapsamlÄ± Veri Toplama
- **Product Information**: ÃœrÃ¼n adÄ±, marka, kategori, fiyat bilgileri
- **Ingredient Analysis**: DetaylÄ± ingredient analizi ve CosIng entegrasyonu
- **Image Processing**: Otomatik resim indirme ve optimizasyon
- **Function & Free Data**: Ingredient fonksiyonlarÄ± ve serbest veriler

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### Gereksinimler
- Python 3.8+
- Virtual Environment (Ã¶nerilen)

### Kurulum

```bash
# Repository'yi klonlayÄ±n
git clone https://github.com/selmanays/INCIScraper.git
cd INCIScraper

# Virtual environment oluÅŸturun ve aktifleÅŸtirin
python -m venv .venv
source .venv/bin/activate  # Linux/macOS
# .venv\Scripts\activate  # Windows

# BaÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kleyin
pip install -r requirements.txt

# Playwright tarayÄ±cÄ±larÄ±nÄ± yÃ¼kleyin
playwright install
```

### Temel KullanÄ±m

```bash
# Sample data ile test
python main.py --sample-data

# Tam kazÄ±ma (dikkatli kullanÄ±n)
python main.py

# Performans optimizasyonu ile
python main.py --max-workers 4 --batch-size 100
```

## âš™ï¸ Komut SatÄ±rÄ± Parametreleri

### Performans AyarlarÄ±
```bash
--max-workers N        # Paralel HTTP iÅŸÃ§i sayÄ±sÄ± (varsayÄ±lan: 1)
--batch-size N         # Batch boyutu (varsayÄ±lan: 50)
--image-workers N      # Resim iÅŸleme iÅŸÃ§i sayÄ±sÄ± (varsayÄ±lan: 4)
--skip-images          # Resim indirmeyi atla
```

### Veri ve Loglama
```bash
--sample-data          # Sample data kullan
--db-path PATH         # VeritabanÄ± yolu
--log-level LEVEL      # Log seviyesi (DEBUG, INFO, WARNING, ERROR)
```

### Ã–rnek KullanÄ±mlar

```bash
# HÄ±zlÄ± test
python main.py --sample-data --log-level DEBUG

# Maksimum performans
python main.py --max-workers 8 --batch-size 200 --image-workers 8

# Resim olmadan kazÄ±ma
python main.py --skip-images --max-workers 4

# Debug modu
python main.py --sample-data --log-level DEBUG --max-workers 2
```

## ğŸ“Š VeritabanÄ± YapÄ±sÄ±

### Ana Tablolar
- **brands**: Marka bilgileri
- **products**: ÃœrÃ¼n bilgileri
- **ingredients**: Ingredient detaylarÄ±
- **functions**: Ingredient fonksiyonlarÄ±
- **frees**: Serbest veriler

### Ä°liÅŸkiler
- Products â†’ Brands (many-to-one)
- Products â†’ Ingredients (many-to-many)
- Ingredients â†’ Functions (many-to-many)
- Ingredients â†’ Frees (one-to-many)

## ğŸ¯ Performans OptimizasyonlarÄ±

### 1. Paralel HTTP Ä°stekleri
```python
# ThreadPoolExecutor ile eÅŸzamanlÄ± kazÄ±ma
max_workers = 4  # 4 paralel iÅŸÃ§i
```

### 2. Adaptive Rate Limiting
```python
# Dinamik gecikme yÃ¶netimi
min_rate_limit = 0.1  # Minimum gecikme (saniye)
max_rate_limit = 2.0  # Maksimum gecikme (saniye)
```

### 3. Batch Database Operations
```python
# Toplu veritabanÄ± iÅŸlemleri
batch_size = 50  # 50 Ã¶ÄŸe per batch
```

### 4. LRU Cache
```python
# Bellek tabanlÄ± Ã¶nbellekleme
cache_size_limit = 10000  # 10K Ã¶ÄŸe cache
```

### 5. CosIng Optimizasyonu
```python
# Optimize edilmiÅŸ Playwright kullanÄ±mÄ±
# - Reduced timeouts
# - Smart fallback strategy
# - Multiple selector fallback
```

## ğŸ“ˆ Performans Metrikleri

### HÄ±z Ä°yileÅŸtirmeleri
- **CosIng Scraping**: 24s â†’ 3-6s (%60 hÄ±zlanma)
- **HTTP Requests**: 300-500% hÄ±z artÄ±ÅŸÄ±
- **Database Operations**: 200-400% hÄ±z artÄ±ÅŸÄ±
- **Image Processing**: 200-300% hÄ±z artÄ±ÅŸÄ±
- **Overall Speed**: 200-400% genel iyileÅŸtirme

### Kaynak KullanÄ±mÄ±
- **Memory**: LRU cache ile optimize edilmiÅŸ bellek kullanÄ±mÄ±
- **CPU**: Paralel iÅŸleme ile CPU kullanÄ±mÄ± artÄ±rÄ±ldÄ±
- **Network**: Adaptive rate limiting ile aÄŸ trafiÄŸi optimize edildi
- **Storage**: Batch operations ile disk I/O azaltÄ±ldÄ±

## ğŸ”§ GeliÅŸtirme

### Proje YapÄ±sÄ±
```
INCIScraper/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ inciscraper/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ scraper.py          # Ana scraper sÄ±nÄ±fÄ±
â”‚       â”œâ”€â”€ constants.py        # Sabitler
â”‚       â””â”€â”€ mixins/
â”‚           â”œâ”€â”€ database.py     # VeritabanÄ± iÅŸlemleri
â”‚           â”œâ”€â”€ network.py      # HTTP ve aÄŸ iÅŸlemleri
â”‚           â”œâ”€â”€ products.py     # ÃœrÃ¼n kazÄ±ma
â”‚           â”œâ”€â”€ details.py      # Detay kazÄ±ma
â”‚           â””â”€â”€ monitoring.py   # Ä°zleme ve metrikler
â”œâ”€â”€ ui/                         # Next.js web arayÃ¼zÃ¼
â”œâ”€â”€ data/                       # VeritabanÄ± ve loglar
â”œâ”€â”€ main.py                     # CLI giriÅŸ noktasÄ±
â””â”€â”€ requirements.txt            # Python baÄŸÄ±mlÄ±lÄ±klarÄ±
```

### Mixin Mimarisi
INCIScraper, modÃ¼ler mixin mimarisi kullanÄ±r:

- **DatabaseMixin**: VeritabanÄ± iÅŸlemleri
- **NetworkMixin**: HTTP istekleri ve aÄŸ iÅŸlemleri
- **ProductScraperMixin**: ÃœrÃ¼n listesi kazÄ±ma
- **DetailScraperMixin**: ÃœrÃ¼n detay kazÄ±ma
- **MonitoringMixin**: Ä°lerleme takibi ve metrikler

## ğŸ› Sorun Giderme

### YaygÄ±n Sorunlar

#### 1. Playwright Kurulum Sorunu
```bash
# Playwright tarayÄ±cÄ±larÄ±nÄ± yeniden yÃ¼kleyin
playwright install
```

#### 2. SQLite Thread Safety
```bash
# Tek iÅŸÃ§i ile Ã§alÄ±ÅŸtÄ±rÄ±n
python main.py --max-workers 1
```

#### 3. Memory Issues
```bash
# Batch boyutunu azaltÄ±n
python main.py --batch-size 25
```

#### 4. Network Timeouts
```bash
# Debug modu ile detaylÄ± loglar
python main.py --log-level DEBUG
```

### Log DosyalarÄ±
- **Ana Log**: `data/logs/inciscraper.log`
- **Debug Logs**: Console output ile `--log-level DEBUG`

## ğŸ¤ KatkÄ±da Bulunma

1. Fork yapÄ±n
2. Feature branch oluÅŸturun (`git checkout -b feature/amazing-feature`)
3. Commit yapÄ±n (`git commit -m 'Add amazing feature'`)
4. Push yapÄ±n (`git push origin feature/amazing-feature`)
5. Pull Request oluÅŸturun

## ğŸ“„ Lisans

Bu proje MIT lisansÄ± altÄ±nda lisanslanmÄ±ÅŸtÄ±r. Detaylar iÃ§in `LICENSE` dosyasÄ±na bakÄ±n.

## ğŸ™ TeÅŸekkÃ¼rler

- [INCIDecoder.com](https://incidecoder.com) - Veri kaynaÄŸÄ±
- [EU CosIng Database](https://ec.europa.eu/growth/tools-databases/cosing/) - Ingredient veritabanÄ±
- [Playwright](https://playwright.dev/) - Web automation
- [SQLite](https://sqlite.org/) - VeritabanÄ±

## ğŸ“ Ä°letiÅŸim

- **GitHub**: [selmanays/INCIScraper](https://github.com/selmanays/INCIScraper)
- **Issues**: [GitHub Issues](https://github.com/selmanays/INCIScraper/issues)

---

**âš ï¸ UyarÄ±**: Bu araÃ§ yalnÄ±zca eÄŸitim ve araÅŸtÄ±rma amaÃ§lÄ±dÄ±r. Web sitelerinin kullanÄ±m ÅŸartlarÄ±na uygun ÅŸekilde kullanÄ±n ve rate limiting'e dikkat edin.
